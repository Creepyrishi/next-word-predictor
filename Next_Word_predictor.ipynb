{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1Mpyt6IY8sR",
        "outputId": "62dc94bd-4496-4e1e-a970-949d0a9fd9c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: emoji in /usr/local/lib/python3.11/dist-packages (2.14.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install emoji"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "xh0ub65UT0jE"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from nltk import word_tokenize\n",
        "import emoji\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.nn.functional import one_hot\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch import nn\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "else:\n",
        "  device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "id": "cnUNjSSCR_T8"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBKX0M16XGfl",
        "outputId": "516fda2d-bb12-43e7-fb92-dcbeed885207"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "RqxTqc1CbbI7"
      },
      "outputs": [],
      "source": [
        "paths = [\"./pickup_lines_all.txt\",]\n",
        "for path in paths:\n",
        "    with open(path, 'r', encoding='utf-8', errors='ignore') as f:\n",
        "        raw_txt = f.read()\n",
        "\n",
        "    # with open(\"./text.txt\", 'a', encoding='utf-8', errors='ignore') as t:\n",
        "    #     for txt in raw_txt.splitlines():\n",
        "    #         t.write(txt)\n",
        "    #         t.write('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "dPpsLIZin1qt"
      },
      "outputs": [],
      "source": [
        "def load_interjection(path):\n",
        "  interjection = []\n",
        "  with open(path, 'r', encoding='utf-8', errors = 'ignore') as f:\n",
        "    txt = f.read().splitlines()\n",
        "    for word in txt:\n",
        "      interjection.append(word)\n",
        "      return interjection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "-QldE6UIXl95"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    # 1. Remove emojis\n",
        "    text = emoji.replace_emoji(text, replace='')\n",
        "\n",
        "    # 2. Remove sequences of multiple dots like ... or .... etc\n",
        "    text = re.sub(r'\\.', '', text)\n",
        "\n",
        "    # 3. Remove all punctuation except single full stops\n",
        "    # Keep letters, numbers, spaces, and single periods\n",
        "    text = re.sub(r'[^\\w\\s.]', '', text)\n",
        "\n",
        "    # 4. Normalize whitespace\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    # 5. Tokenize\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "HA0FSLa4Xbbi"
      },
      "outputs": [],
      "source": [
        "txt = open(\"./pickup_lines_all.txt\", 'r', encoding='utf-8', errors='ignore').read().split('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "7CSmx7f_ZVke"
      },
      "outputs": [],
      "source": [
        "tokenized_txt = []\n",
        "for line in txt:\n",
        "    tokenized_txt.append(clean_text(line))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "i40Xu556beB7"
      },
      "outputs": [],
      "source": [
        "all_words = []\n",
        "for sentence in tokenized_txt:\n",
        "  for word in sentence:\n",
        "    all_words.append(word.lower())\n",
        "all_words= set(all_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "KI0i2na4mG8U"
      },
      "outputs": [],
      "source": [
        "word_dict = {}\n",
        "for i, word in enumerate(sorted(all_words)):\n",
        "  word_dict[word] = i+1\n",
        "i_to_w = {v: k for k, v in word_dict.items()}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(word_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MVzMG5cCdFC",
        "outputId": "df89e036-d491-4971-8280-bb3345af831a"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2064"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0ngidVGz-nH",
        "outputId": "eeffcb56-7c6b-4501-8064-a21eb7f35d67"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'1': 1,\n",
              " '10': 2,\n",
              " '100': 3,\n",
              " '101': 4,\n",
              " '105': 5,\n",
              " '106': 6,\n",
              " '118': 7,\n",
              " '12': 8,\n",
              " '120': 9,\n",
              " '122': 10,\n",
              " '17': 11,\n",
              " '19': 12,\n",
              " '20': 13,\n",
              " '2025': 14,\n",
              " '2025read': 15,\n",
              " '25': 16,\n",
              " '27': 17,\n",
              " '3': 18,\n",
              " '30': 19,\n",
              " '31': 20,\n",
              " '33': 21,\n",
              " '45degree': 22,\n",
              " '4th': 23,\n",
              " '5': 24,\n",
              " '50': 25,\n",
              " '6': 26,\n",
              " '60': 27,\n",
              " '65': 28,\n",
              " '7': 29,\n",
              " '70': 30,\n",
              " '73': 31,\n",
              " '75': 32,\n",
              " '83': 33,\n",
              " '90': 34,\n",
              " '90s': 35,\n",
              " '96': 36,\n",
              " 'a': 37,\n",
              " 'abducted': 38,\n",
              " 'ablaze': 39,\n",
              " 'able': 40,\n",
              " 'about': 41,\n",
              " 'abraham': 42,\n",
              " 'absolutely': 43,\n",
              " 'ace': 44,\n",
              " 'aces': 45,\n",
              " 'aching': 46,\n",
              " 'across': 47,\n",
              " 'activity': 48,\n",
              " 'acts': 49,\n",
              " 'actually': 50,\n",
              " 'acute': 51,\n",
              " 'acutie': 52,\n",
              " 'add': 53,\n",
              " 'additionally': 54,\n",
              " 'admire': 55,\n",
              " 'admire270': 56,\n",
              " 'admirelove': 57,\n",
              " 'admirely': 58,\n",
              " 'admirer': 59,\n",
              " 'adopt': 60,\n",
              " 'adore': 61,\n",
              " 'adore270': 62,\n",
              " 'adorelove': 63,\n",
              " 'adorely': 64,\n",
              " 'adventure': 65,\n",
              " 'adventurous': 66,\n",
              " 'af': 67,\n",
              " 'affection': 68,\n",
              " 'affectionsand': 69,\n",
              " 'africa': 70,\n",
              " 'after': 71,\n",
              " 'afterward': 72,\n",
              " 'again': 73,\n",
              " 'against': 74,\n",
              " 'agile': 75,\n",
              " 'ago': 76,\n",
              " 'agreed': 77,\n",
              " 'ahead': 78,\n",
              " 'ai': 79,\n",
              " 'aipowered': 80,\n",
              " 'air': 81,\n",
              " 'airplane': 82,\n",
              " 'airport': 83,\n",
              " 'ali': 84,\n",
              " 'alien': 85,\n",
              " 'alist': 86,\n",
              " 'all': 87,\n",
              " 'almost': 88,\n",
              " 'along': 89,\n",
              " 'alongside': 90,\n",
              " 'aloud': 91,\n",
              " 'alphabet': 92,\n",
              " 'already': 93,\n",
              " 'also': 94,\n",
              " 'always': 95,\n",
              " 'am': 96,\n",
              " 'amazing': 97,\n",
              " 'an': 98,\n",
              " 'and': 99,\n",
              " 'angel': 100,\n",
              " 'angels': 101,\n",
              " 'angle': 102,\n",
              " 'animal': 103,\n",
              " 'anime': 104,\n",
              " 'anniversary': 105,\n",
              " 'anniversarycool': 106,\n",
              " 'announcement': 107,\n",
              " 'annoyed': 108,\n",
              " 'any': 109,\n",
              " 'anymore': 110,\n",
              " 'anyone': 111,\n",
              " 'apeeling': 112,\n",
              " 'apocalypse': 113,\n",
              " 'app': 114,\n",
              " 'appeared': 115,\n",
              " 'appendix': 116,\n",
              " 'appreciate': 117,\n",
              " 'appreciate270': 118,\n",
              " 'appreciatelove': 119,\n",
              " 'approved': 120,\n",
              " 'archaeologist': 121,\n",
              " 'are': 122,\n",
              " 'arent': 123,\n",
              " 'arms': 124,\n",
              " 'around': 125,\n",
              " 'arsenal': 126,\n",
              " 'article': 127,\n",
              " 'artist': 128,\n",
              " 'as': 129,\n",
              " 'asf': 130,\n",
              " 'aside': 131,\n",
              " 'ask': 132,\n",
              " 'asking': 133,\n",
              " 'asleep': 134,\n",
              " 'ass': 135,\n",
              " 'assistant': 136,\n",
              " 'at': 137,\n",
              " 'att': 138,\n",
              " 'attention': 139,\n",
              " 'attractive': 140,\n",
              " 'australian': 141,\n",
              " 'autocomplete': 142,\n",
              " 'away': 143,\n",
              " 'awe': 144,\n",
              " 'awesome': 145,\n",
              " 'awkward': 146,\n",
              " 'awww': 147,\n",
              " 'baby': 148,\n",
              " 'babymaking': 149,\n",
              " 'back': 150,\n",
              " 'backtracking': 151,\n",
              " 'backwhats': 152,\n",
              " 'bacon': 153,\n",
              " 'bad': 154,\n",
              " 'baker': 155,\n",
              " 'bakers': 156,\n",
              " 'bakery': 157,\n",
              " 'balcony': 158,\n",
              " 'ball': 159,\n",
              " 'balls': 160,\n",
              " 'banana': 161,\n",
              " 'band': 162,\n",
              " 'bandaid': 163,\n",
              " 'bang': 164,\n",
              " 'bank': 165,\n",
              " 'bar': 166,\n",
              " 'barbie': 167,\n",
              " 'baste': 168,\n",
              " 'battlefield': 169,\n",
              " 'bc7': 170,\n",
              " 'be': 171,\n",
              " 'beach': 172,\n",
              " 'beaches': 173,\n",
              " 'beadmired': 174,\n",
              " 'beadored': 175,\n",
              " 'beappreciated': 176,\n",
              " 'beautiful': 177,\n",
              " 'beauty': 178,\n",
              " 'beaver': 179,\n",
              " 'because': 180,\n",
              " 'becherishd': 181,\n",
              " 'bed': 182,\n",
              " 'bedesired': 183,\n",
              " 'been': 184,\n",
              " 'beer': 185,\n",
              " 'before': 186,\n",
              " 'behaviors': 187,\n",
              " 'being': 188,\n",
              " 'bela': 189,\n",
              " 'believe': 190,\n",
              " 'belong': 191,\n",
              " 'belonged': 192,\n",
              " 'beloved': 193,\n",
              " 'below': 194,\n",
              " 'belt': 195,\n",
              " 'ben': 196,\n",
              " 'bend': 197,\n",
              " 'best': 198,\n",
              " 'bet': 199,\n",
              " 'betreasured': 200,\n",
              " 'better': 201,\n",
              " 'between': 202,\n",
              " 'beys': 203,\n",
              " 'big': 204,\n",
              " 'bill': 205,\n",
              " 'bio': 206,\n",
              " 'biography': 207,\n",
              " 'bird': 208,\n",
              " 'bit': 209,\n",
              " 'bite': 210,\n",
              " 'bites': 211,\n",
              " 'blanket': 212,\n",
              " 'bless': 213,\n",
              " 'blessing': 214,\n",
              " 'blinded': 215,\n",
              " 'blinding': 216,\n",
              " 'block': 217,\n",
              " 'blog': 218,\n",
              " 'blowing': 219,\n",
              " 'boat': 220,\n",
              " 'body': 221,\n",
              " 'boiling': 222,\n",
              " 'bold': 223,\n",
              " 'bond': 224,\n",
              " 'bone': 225,\n",
              " 'boobs': 226,\n",
              " 'book': 227,\n",
              " 'boring': 228,\n",
              " 'boris': 229,\n",
              " 'borrow': 230,\n",
              " 'boss': 231,\n",
              " 'both': 232,\n",
              " 'bother': 233,\n",
              " 'bothered': 234,\n",
              " 'bounce': 235,\n",
              " 'bowling': 236,\n",
              " 'boxer': 237,\n",
              " 'boyfriend': 238,\n",
              " 'boyfriend95': 239,\n",
              " 'boyfriends20': 240,\n",
              " 'bra': 241,\n",
              " 'bradley': 242,\n",
              " 'brands': 243,\n",
              " 'brave': 244,\n",
              " 'bravery': 245,\n",
              " 'break': 246,\n",
              " 'breakfast': 247,\n",
              " 'breaks': 248,\n",
              " 'breath': 249,\n",
              " 'breathtaking': 250,\n",
              " 'bride': 251,\n",
              " 'brighter': 252,\n",
              " 'bring': 253,\n",
              " 'bringing': 254,\n",
              " 'brings': 255,\n",
              " 'brink': 256,\n",
              " 'broken': 257,\n",
              " 'brood': 258,\n",
              " 'brook': 259,\n",
              " 'brooks': 260,\n",
              " 'broom': 261,\n",
              " 'brother': 262,\n",
              " 'browning': 263,\n",
              " 'brushing': 264,\n",
              " 'bubble': 265,\n",
              " 'bucks': 266,\n",
              " 'buddies': 267,\n",
              " 'bumble': 268,\n",
              " 'buns': 269,\n",
              " 'burger': 270,\n",
              " 'burglar': 271,\n",
              " 'burn': 272,\n",
              " 'burning': 273,\n",
              " 'burns': 274,\n",
              " 'business': 275,\n",
              " 'busmans': 276,\n",
              " 'but': 277,\n",
              " 'butt': 278,\n",
              " 'buttdialing': 279,\n",
              " 'butterflies': 280,\n",
              " 'button': 281,\n",
              " 'buttons': 282,\n",
              " 'buy': 283,\n",
              " 'by': 284,\n",
              " 'cackling': 285,\n",
              " 'cage': 286,\n",
              " 'cake': 287,\n",
              " 'call': 288,\n",
              " 'called': 289,\n",
              " 'calling': 290,\n",
              " 'calm': 291,\n",
              " 'calories': 292,\n",
              " 'cameo': 293,\n",
              " 'camera': 294,\n",
              " 'camp': 295,\n",
              " 'campfire': 296,\n",
              " 'can': 297,\n",
              " 'candy': 298,\n",
              " 'cane': 299,\n",
              " 'cant': 300,\n",
              " 'canyon': 301,\n",
              " 'captain': 302,\n",
              " 'captions': 303,\n",
              " 'captivating': 304,\n",
              " 'capture': 305,\n",
              " 'captured': 306,\n",
              " 'carbon': 307,\n",
              " 'card': 308,\n",
              " 'care': 309,\n",
              " 'carefully': 310,\n",
              " 'carey': 311,\n",
              " 'cast': 312,\n",
              " 'casualtaylor': 313,\n",
              " 'cat': 314,\n",
              " 'catch': 315,\n",
              " 'catchy': 316,\n",
              " 'cause': 317,\n",
              " 'celebrate': 318,\n",
              " 'celebrity': 319,\n",
              " 'cell': 320,\n",
              " 'chamber': 321,\n",
              " 'chamomile': 322,\n",
              " 'champagne': 323,\n",
              " 'chance': 324,\n",
              " 'chances': 325,\n",
              " 'change': 326,\n",
              " 'changed': 327,\n",
              " 'chaos': 328,\n",
              " 'chapter': 329,\n",
              " 'character': 330,\n",
              " 'charge': 331,\n",
              " 'charger': 332,\n",
              " 'charges': 333,\n",
              " 'charm': 334,\n",
              " 'charming': 335,\n",
              " 'charms': 336,\n",
              " 'chase': 337,\n",
              " 'chatgpt': 338,\n",
              " 'cheat': 339,\n",
              " 'cheating': 340,\n",
              " 'check': 341,\n",
              " 'checking': 342,\n",
              " 'cheeky': 343,\n",
              " 'cheese': 344,\n",
              " 'cheesy': 345,\n",
              " 'chemistry': 346,\n",
              " 'cherish': 347,\n",
              " 'cherish270': 348,\n",
              " 'cherishlove': 349,\n",
              " 'cherry': 350,\n",
              " 'chimney': 351,\n",
              " 'chocolate': 352,\n",
              " 'choose': 353,\n",
              " 'chopper': 354,\n",
              " 'choppers': 355,\n",
              " 'christmas': 356,\n",
              " 'cigarette': 357,\n",
              " 'clapton': 358,\n",
              " 'class': 359,\n",
              " 'classics': 360,\n",
              " 'clear': 361,\n",
              " 'clearly': 362,\n",
              " 'clever': 363,\n",
              " 'close': 364,\n",
              " 'clothes': 365,\n",
              " 'clumsiness': 366,\n",
              " 'cock': 367,\n",
              " 'coffee': 368,\n",
              " 'coin': 369,\n",
              " 'cold': 370,\n",
              " 'cole': 371,\n",
              " 'color': 372,\n",
              " 'colors': 373,\n",
              " 'combination': 374,\n",
              " 'combined': 375,\n",
              " 'combo': 376,\n",
              " 'come': 377,\n",
              " 'comedy': 378,\n",
              " 'comes': 379,\n",
              " 'coming': 380,\n",
              " 'command': 381,\n",
              " 'common': 382,\n",
              " 'communicate': 383,\n",
              " 'community': 384,\n",
              " 'compact': 385,\n",
              " 'company': 386,\n",
              " 'compare': 387,\n",
              " 'compassionate': 388,\n",
              " 'compatible': 389,\n",
              " 'competition': 390,\n",
              " 'complete': 391,\n",
              " 'completely': 392,\n",
              " 'computer': 393,\n",
              " 'concerned': 394,\n",
              " 'concrete': 395,\n",
              " 'conditioning': 396,\n",
              " 'condoms': 397,\n",
              " 'confidence': 398,\n",
              " 'confident': 399,\n",
              " 'connect': 400,\n",
              " 'connection': 401,\n",
              " 'consider': 402,\n",
              " 'constipated': 403,\n",
              " 'contact': 404,\n",
              " 'contract': 405,\n",
              " 'conversation': 406,\n",
              " 'conversations': 407,\n",
              " 'cooking': 408,\n",
              " 'cool': 409,\n",
              " 'cooler': 410,\n",
              " 'cooper': 411,\n",
              " 'copy': 412,\n",
              " 'cork': 413,\n",
              " 'cornfield': 414,\n",
              " 'could': 415,\n",
              " 'couldnt': 416,\n",
              " 'couldve': 417,\n",
              " 'couple': 418,\n",
              " 'couples': 419,\n",
              " 'course': 420,\n",
              " 'cowgirl': 421,\n",
              " 'cpr': 422,\n",
              " 'craft': 423,\n",
              " 'crazy': 424,\n",
              " 'cream': 425,\n",
              " 'creampie': 426,\n",
              " 'create': 427,\n",
              " 'creature': 428,\n",
              " 'crew': 429,\n",
              " 'cringy': 430,\n",
              " 'crisis': 431,\n",
              " 'crowd': 432,\n",
              " 'crush': 433,\n",
              " 'crushdoes': 434,\n",
              " 'crushs': 435,\n",
              " 'crushthese': 436,\n",
              " 'crushyour': 437,\n",
              " 'cup': 438,\n",
              " 'cure': 439,\n",
              " 'currently': 440,\n",
              " 'curse': 441,\n",
              " 'curves': 442,\n",
              " 'cute': 443,\n",
              " 'cutecumber': 444,\n",
              " 'cutest': 445,\n",
              " 'cutie': 446,\n",
              " 'cyclops': 447,\n",
              " 'd': 448,\n",
              " 'daaaaaaaaam': 449,\n",
              " 'dad': 450,\n",
              " 'dam': 451,\n",
              " 'damme': 452,\n",
              " 'damn': 453,\n",
              " 'damnnndelion': 454,\n",
              " 'dan': 455,\n",
              " 'danced': 456,\n",
              " 'dancer': 457,\n",
              " 'dangerous': 458,\n",
              " 'dare': 459,\n",
              " 'data': 460,\n",
              " 'date': 461,\n",
              " 'dates': 462,\n",
              " 'dating': 463,\n",
              " 'davy': 464,\n",
              " 'day': 465,\n",
              " 'daycare': 466,\n",
              " 'daycarrie': 467,\n",
              " 'days': 468,\n",
              " 'dead': 469,\n",
              " 'death': 470,\n",
              " 'decision': 471,\n",
              " 'decrease': 472,\n",
              " 'deep': 473,\n",
              " 'deeper': 474,\n",
              " 'defenses': 475,\n",
              " 'definitely': 476,\n",
              " 'degree': 477,\n",
              " 'del': 478,\n",
              " 'delicate': 479,\n",
              " 'delicious': 480,\n",
              " 'dementia': 481,\n",
              " 'denden': 482,\n",
              " 'dentist': 483,\n",
              " 'depot': 484,\n",
              " 'describe': 485,\n",
              " 'deserted': 486,\n",
              " 'design': 487,\n",
              " 'designer': 488,\n",
              " 'desire': 489,\n",
              " 'desire270': 490,\n",
              " 'desirelove': 491,\n",
              " 'desk': 492,\n",
              " 'destined': 493,\n",
              " 'detailed': 494,\n",
              " 'devil': 495,\n",
              " 'dick': 496,\n",
              " 'dicks': 497,\n",
              " 'dictionary': 498,\n",
              " 'did': 499,\n",
              " 'didnt': 500,\n",
              " 'different': 501,\n",
              " 'difficult': 502,\n",
              " 'digits': 503,\n",
              " 'dinner': 504,\n",
              " 'dinosaurs': 505,\n",
              " 'dipping': 506,\n",
              " 'direct': 507,\n",
              " 'directions': 508,\n",
              " 'dirty': 509,\n",
              " 'disappear': 510,\n",
              " 'disappeared': 511,\n",
              " 'disappears': 512,\n",
              " 'disappoint': 513,\n",
              " 'disease': 514,\n",
              " 'dish': 515,\n",
              " 'distancing': 516,\n",
              " 'distancingfine': 517,\n",
              " 'distancinggorgeous': 518,\n",
              " 'distancinghot': 519,\n",
              " 'distancingirresistible': 520,\n",
              " 'distancingradiant': 521,\n",
              " 'distancingsexy': 522,\n",
              " 'distancingstunning': 523,\n",
              " 'distracting': 524,\n",
              " 'divorced': 525,\n",
              " 'dms': 526,\n",
              " 'dna': 527,\n",
              " 'do': 528,\n",
              " 'doctor': 529,\n",
              " 'doctors': 530,\n",
              " 'does': 531,\n",
              " 'doesnt': 532,\n",
              " 'dog': 533,\n",
              " 'dogs': 534,\n",
              " 'doing': 535,\n",
              " 'done': 536,\n",
              " 'dont': 537,\n",
              " 'doodle': 538,\n",
              " 'door': 539,\n",
              " 'dorothy': 540,\n",
              " 'doublestuff': 541,\n",
              " 'down': 542,\n",
              " 'dr': 543,\n",
              " 'dragon': 544,\n",
              " 'dragons': 545,\n",
              " 'drawing': 546,\n",
              " 'dream': 547,\n",
              " 'dreamhouse': 548,\n",
              " 'dreaming': 549,\n",
              " 'dreams': 550,\n",
              " 'dreams55': 551,\n",
              " 'drill': 552,\n",
              " 'drink': 553,\n",
              " 'drinks': 554,\n",
              " 'dripping': 555,\n",
              " 'driving': 556,\n",
              " 'drop': 557,\n",
              " 'dropdead': 558,\n",
              " 'dropped': 559,\n",
              " 'dry': 560,\n",
              " 'duck': 561,\n",
              " 'ducksized': 562,\n",
              " 'dumbledore': 563,\n",
              " 'dumped': 564,\n",
              " 'during': 565,\n",
              " 'dying': 566,\n",
              " 'each': 567,\n",
              " 'early': 568,\n",
              " 'earth': 569,\n",
              " 'easy': 570,\n",
              " 'eat': 571,\n",
              " 'eating': 572,\n",
              " 'echoes': 573,\n",
              " 'education11': 574,\n",
              " 'effective': 575,\n",
              " 'effort': 576,\n",
              " 'eggs': 577,\n",
              " 'eiffel': 578,\n",
              " 'either': 579,\n",
              " 'elegance': 580,\n",
              " 'elevator': 581,\n",
              " 'else': 582,\n",
              " 'embark': 583,\n",
              " 'emerald': 584,\n",
              " 'emojis': 585,\n",
              " 'end': 586,\n",
              " 'endless': 587,\n",
              " 'energy': 588,\n",
              " 'engagedtimmy': 589,\n",
              " 'engagement': 590,\n",
              " 'enjoy': 591,\n",
              " 'enough': 592,\n",
              " 'ensure': 593,\n",
              " 'entered': 594,\n",
              " 'entrancing': 595,\n",
              " 'eric': 596,\n",
              " 'escape': 597,\n",
              " 'especially': 598,\n",
              " 'even': 599,\n",
              " 'ever': 600,\n",
              " 'every': 601,\n",
              " 'everyone': 602,\n",
              " 'everything': 603,\n",
              " 'evil': 604,\n",
              " 'ex': 605,\n",
              " 'exact': 606,\n",
              " 'exactly': 607,\n",
              " 'exaggerated': 608,\n",
              " 'exam': 609,\n",
              " 'examination': 610,\n",
              " 'examine': 611,\n",
              " 'except': 612,\n",
              " 'excess': 613,\n",
              " 'excuse': 614,\n",
              " 'excuses': 615,\n",
              " 'exist': 616,\n",
              " 'existed': 617,\n",
              " 'existential': 618,\n",
              " 'expect': 619,\n",
              " 'expire': 620,\n",
              " 'explain': 621,\n",
              " 'explained': 622,\n",
              " 'explore': 623,\n",
              " 'express': 624,\n",
              " 'extra': 625,\n",
              " 'eye': 626,\n",
              " 'eyes': 627,\n",
              " 'ezra': 628,\n",
              " 'face': 629,\n",
              " 'faintdayed': 630,\n",
              " 'fainthearted': 631,\n",
              " 'faintlifeed': 632,\n",
              " 'faintminded': 633,\n",
              " 'faintsouled': 634,\n",
              " 'faintuniverseed': 635,\n",
              " 'faintworlded': 636,\n",
              " 'fair': 637,\n",
              " 'fall': 638,\n",
              " 'fallen': 639,\n",
              " 'fallin': 640,\n",
              " 'falling': 641,\n",
              " 'familiar': 642,\n",
              " 'familiardid': 643,\n",
              " 'family': 644,\n",
              " 'fans': 645,\n",
              " 'fantasy': 646,\n",
              " 'farmer': 647,\n",
              " 'fast': 648,\n",
              " 'fate': 649,\n",
              " 'favorite': 650,\n",
              " 'fbi': 651,\n",
              " 'fck': 652,\n",
              " 'fda': 653,\n",
              " 'fear': 654,\n",
              " 'feathers': 655,\n",
              " 'feed': 656,\n",
              " 'feedback': 657,\n",
              " 'feel': 658,\n",
              " 'feeling': 659,\n",
              " 'feels': 660,\n",
              " 'feet': 661,\n",
              " 'feisty': 662,\n",
              " 'fell': 663,\n",
              " 'felt': 664,\n",
              " 'fertilized': 665,\n",
              " 'few': 666,\n",
              " 'fictional': 667,\n",
              " 'fight': 668,\n",
              " 'figure': 669,\n",
              " 'figuring': 670,\n",
              " 'fill': 671,\n",
              " 'finally': 672,\n",
              " 'find': 673,\n",
              " 'finding': 674,\n",
              " 'fine': 675,\n",
              " 'fineness': 676,\n",
              " 'finetest': 677,\n",
              " 'finger': 678,\n",
              " 'fingers': 679,\n",
              " 'fingertips': 680,\n",
              " 'finish': 681,\n",
              " 'fire': 682,\n",
              " 'fired': 683,\n",
              " 'first': 684,\n",
              " 'fishman': 685,\n",
              " 'fits': 686,\n",
              " 'five': 687,\n",
              " 'flags': 688,\n",
              " 'flappy': 689,\n",
              " 'flashback': 690,\n",
              " 'flatscreen': 691,\n",
              " 'flavor': 692,\n",
              " 'flavorwhat': 693,\n",
              " 'flexible': 694,\n",
              " 'flick': 695,\n",
              " 'flip': 696,\n",
              " 'flirt': 697,\n",
              " 'flirting': 698,\n",
              " 'flirty': 699,\n",
              " 'flow': 700,\n",
              " 'flower': 701,\n",
              " 'fly': 702,\n",
              " 'folks': 703,\n",
              " 'follow': 704,\n",
              " 'followup': 705,\n",
              " 'footlong': 706,\n",
              " 'for': 707,\n",
              " 'forbidden': 708,\n",
              " 'force': 709,\n",
              " 'forever': 710,\n",
              " 'forget': 711,\n",
              " 'forgot': 712,\n",
              " 'form': 713,\n",
              " 'forman': 714,\n",
              " 'forming': 715,\n",
              " 'forward': 716,\n",
              " 'four': 717,\n",
              " 'france': 718,\n",
              " 'frankys': 719,\n",
              " 'free': 720,\n",
              " 'french': 721,\n",
              " 'friday': 722,\n",
              " 'friend': 723,\n",
              " 'frienddoes': 724,\n",
              " 'friendly': 725,\n",
              " 'friends': 726,\n",
              " 'friendship': 727,\n",
              " 'from': 728,\n",
              " 'fruit': 729,\n",
              " 'fun': 730,\n",
              " 'funny': 731,\n",
              " 'fur': 732,\n",
              " 'furry': 733,\n",
              " 'further': 734,\n",
              " 'future': 735,\n",
              " 'gag': 736,\n",
              " 'game': 737,\n",
              " 'games': 738,\n",
              " 'gave': 739,\n",
              " 'gayle': 740,\n",
              " 'gaze': 741,\n",
              " 'generally': 742,\n",
              " 'generating': 743,\n",
              " 'genes': 744,\n",
              " 'genius': 745,\n",
              " 'get': 746,\n",
              " 'gets': 747,\n",
              " 'getting': 748,\n",
              " 'ghost': 749,\n",
              " 'ghosts': 750,\n",
              " 'gibran': 751,\n",
              " 'gifts': 752,\n",
              " 'gigi': 753,\n",
              " 'girl': 754,\n",
              " 'girlfriend': 755,\n",
              " 'girlfriend124': 756,\n",
              " 'give': 757,\n",
              " 'given': 758,\n",
              " 'giving': 759,\n",
              " 'glad': 760,\n",
              " 'gladly': 761,\n",
              " 'global': 762,\n",
              " 'glorious': 763,\n",
              " 'glow': 764,\n",
              " 'go': 765,\n",
              " 'god': 766,\n",
              " 'goddess': 767,\n",
              " 'goddesss': 768,\n",
              " 'goes': 769,\n",
              " 'going': 770,\n",
              " 'gold': 771,\n",
              " 'golden': 772,\n",
              " 'goldman': 773,\n",
              " 'gon': 774,\n",
              " 'good': 775,\n",
              " 'goodlooking': 776,\n",
              " 'goods': 777,\n",
              " 'google': 778,\n",
              " 'gorgeous': 779,\n",
              " 'gorgeousness': 780,\n",
              " 'gorgeouss': 781,\n",
              " 'gorgeoustest': 782,\n",
              " 'got': 783,\n",
              " 'goto': 784,\n",
              " 'gouda': 785,\n",
              " 'grace': 786,\n",
              " 'graceful': 787,\n",
              " 'grades': 788,\n",
              " 'grain': 789,\n",
              " 'grand': 790,\n",
              " 'great': 791,\n",
              " 'grey': 792,\n",
              " 'grocery': 793,\n",
              " 'group': 794,\n",
              " 'grow': 795,\n",
              " 'guaranteed': 796,\n",
              " 'guess': 797,\n",
              " 'guide': 798,\n",
              " 'guilt': 799,\n",
              " 'guitar': 800,\n",
              " 'guy': 801,\n",
              " 'guys': 802,\n",
              " 'gym': 803,\n",
              " 'had': 804,\n",
              " 'hadid': 805,\n",
              " 'hadnt': 806,\n",
              " 'hair': 807,\n",
              " 'half': 808,\n",
              " 'halfway': 809,\n",
              " 'hancocks': 810,\n",
              " 'hand': 811,\n",
              " 'handle': 812,\n",
              " 'happy': 813,\n",
              " 'hard': 814,\n",
              " 'hardest': 815,\n",
              " 'hardware': 816,\n",
              " 'has': 817,\n",
              " 'hat': 818,\n",
              " 'haunted': 819,\n",
              " 'have': 820,\n",
              " 'having': 821,\n",
              " 'he': 822,\n",
              " 'head': 823,\n",
              " 'headache': 824,\n",
              " 'headaches': 825,\n",
              " 'headmaster': 826,\n",
              " 'health': 827,\n",
              " 'healthy': 828,\n",
              " 'hear': 829,\n",
              " 'heard': 830,\n",
              " 'hearing': 831,\n",
              " 'heart': 832,\n",
              " 'hearts': 833,\n",
              " 'heaven': 834,\n",
              " 'heavenly': 835,\n",
              " 'heavily': 836,\n",
              " 'heavy': 837,\n",
              " 'held': 838,\n",
              " 'hell': 839,\n",
              " 'hell120': 840,\n",
              " 'hello': 841,\n",
              " 'help': 842,\n",
              " 'her': 843,\n",
              " 'here': 844,\n",
              " 'heres': 845,\n",
              " 'hersheys': 846,\n",
              " 'hey': 847,\n",
              " 'hi': 848,\n",
              " 'hide': 849,\n",
              " 'highlights': 850,\n",
              " 'highmaintenance': 851,\n",
              " 'hiking': 852,\n",
              " 'hilarious': 853,\n",
              " 'him': 854,\n",
              " 'hinge': 855,\n",
              " 'his': 856,\n",
              " 'history': 857,\n",
              " 'hit': 858,\n",
              " 'hmm': 859,\n",
              " 'hogwarts': 860,\n",
              " 'hold': 861,\n",
              " 'holding': 862,\n",
              " 'home': 863,\n",
              " 'homework': 864,\n",
              " 'honest': 865,\n",
              " 'honeymoon': 866,\n",
              " 'hooked': 867,\n",
              " 'hope': 868,\n",
              " 'horses': 869,\n",
              " 'horsesized': 870,\n",
              " 'hot': 871,\n",
              " 'hotness': 872,\n",
              " 'hots': 873,\n",
              " 'hottest': 874,\n",
              " 'hour': 875,\n",
              " 'hours': 876,\n",
              " 'house': 877,\n",
              " 'how': 878,\n",
              " 'howd': 879,\n",
              " 'huh': 880,\n",
              " 'humpback': 881,\n",
              " 'hurt': 882,\n",
              " 'husband': 883,\n",
              " 'husbands': 884,\n",
              " 'hypnotic': 885,\n",
              " 'i': 886,\n",
              " 'ice': 887,\n",
              " 'id': 888,\n",
              " 'idea': 889,\n",
              " 'ideal': 890,\n",
              " 'ideas': 891,\n",
              " 'if': 892,\n",
              " 'ifreakin': 893,\n",
              " 'ig': 894,\n",
              " 'ignore': 895,\n",
              " 'ignored': 896,\n",
              " 'ill': 897,\n",
              " 'im': 898,\n",
              " 'imagine': 899,\n",
              " 'important': 900,\n",
              " 'importantdana': 901,\n",
              " 'importantmy': 902,\n",
              " 'impress': 903,\n",
              " 'impression': 904,\n",
              " 'improve': 905,\n",
              " 'in': 906,\n",
              " 'inadequate': 907,\n",
              " 'include': 908,\n",
              " 'increase': 909,\n",
              " 'incredible': 910,\n",
              " 'incredibly': 911,\n",
              " 'independence': 912,\n",
              " 'index': 913,\n",
              " 'inhaler': 914,\n",
              " 'ink': 915,\n",
              " 'innout': 916,\n",
              " 'inside': 917,\n",
              " 'insidious': 918,\n",
              " 'inspiration': 919,\n",
              " 'instagram': 920,\n",
              " 'instagrams': 921,\n",
              " 'instead': 922,\n",
              " 'insurance': 923,\n",
              " 'interest': 924,\n",
              " 'interested': 925,\n",
              " 'interesting': 926,\n",
              " 'into': 927,\n",
              " 'introduce': 928,\n",
              " 'invent': 929,\n",
              " 'invested': 930,\n",
              " 'invite': 931,\n",
              " 'irrational': 932,\n",
              " 'irresistible': 933,\n",
              " 'irresistibleness': 934,\n",
              " 'irresistibles': 935,\n",
              " 'irresistibletest': 936,\n",
              " 'is': 937,\n",
              " 'island': 938,\n",
              " 'isnt': 939,\n",
              " 'it': 940,\n",
              " 'its': 941,\n",
              " 'ive': 942,\n",
              " 'jacksage': 943,\n",
              " 'jail': 944,\n",
              " 'jalapeos': 945,\n",
              " 'japan': 946,\n",
              " 'japanties': 947,\n",
              " 'jd': 948,\n",
              " 'jeanclaude': 949,\n",
              " 'jedi': 950,\n",
              " 'job': 951,\n",
              " 'join': 952,\n",
              " 'juicy': 953,\n",
              " 'july': 954,\n",
              " 'jump': 955,\n",
              " 'just': 956,\n",
              " 'jvke': 957,\n",
              " 'karate': 958,\n",
              " 'karma': 959,\n",
              " 'karmasutra': 960,\n",
              " 'kart': 961,\n",
              " 'kaskade': 962,\n",
              " 'kazoo': 963,\n",
              " 'keep': 964,\n",
              " 'keeper': 965,\n",
              " 'kelcezendaya': 966,\n",
              " 'kellys': 967,\n",
              " 'keyboard': 968,\n",
              " 'khalil': 969,\n",
              " 'kid': 970,\n",
              " 'kids': 971,\n",
              " 'kill': 972,\n",
              " 'kind': 973,\n",
              " 'kinds': 974,\n",
              " 'king': 975,\n",
              " 'kinky': 976,\n",
              " 'kiss': 977,\n",
              " 'kissed': 978,\n",
              " 'kissing': 979,\n",
              " 'kitty': 980,\n",
              " 'knee': 981,\n",
              " 'knees': 982,\n",
              " 'knew': 983,\n",
              " 'knocked': 984,\n",
              " 'knockout': 985,\n",
              " 'knot118': 986,\n",
              " 'knot150': 987,\n",
              " 'knot95': 988,\n",
              " 'know': 989,\n",
              " 'knowing': 990,\n",
              " 'knows': 991,\n",
              " 'koalafications': 992,\n",
              " 'kylie': 993,\n",
              " 'l': 994,\n",
              " 'lack': 995,\n",
              " 'lainie': 996,\n",
              " 'lana': 997,\n",
              " 'land': 998,\n",
              " 'language': 999,\n",
              " 'languages': 1000,\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "cKukp-djpZ1s"
      },
      "outputs": [],
      "source": [
        "num_representation  = []\n",
        "for sentence in tokenized_txt:\n",
        "  num_sent = []\n",
        "  for word in sentence:\n",
        "    num_sent.append(word_dict[word.lower()])\n",
        "  num_representation.append(num_sent)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_representation[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4TcuZI7CMUg",
        "outputId": "68e97465-c162-4421-859d-9afeda95abff"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[528,\n",
              "  2053,\n",
              "  820,\n",
              "  37,\n",
              "  1306,\n",
              "  180,\n",
              "  1533,\n",
              "  2053,\n",
              "  817,\n",
              "  758,\n",
              "  1117,\n",
              "  37,\n",
              "  2000,\n",
              "  1207,\n",
              "  1015,\n",
              "  1238,\n",
              "  1029],\n",
              " [1537,\n",
              "  1117,\n",
              "  37,\n",
              "  1396,\n",
              "  538,\n",
              "  1231,\n",
              "  2058,\n",
              "  1666,\n",
              "  103,\n",
              "  906,\n",
              "  19,\n",
              "  1529,\n",
              "  897,\n",
              "  528,\n",
              "  1794,\n",
              "  1502,\n",
              "  99,\n",
              "  1969,\n",
              "  297,\n",
              "  387,\n",
              "  1257,\n",
              "  1106]]"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "kr0dQgaFrgT2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "569ae8f2-2a3e-42ef-b4e4-04f0d3475e04"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[528, 2053],\n",
              " [528, 2053, 820],\n",
              " [528, 2053, 820, 37],\n",
              " [528, 2053, 820, 37, 1306],\n",
              " [528, 2053, 820, 37, 1306, 180],\n",
              " [528, 2053, 820, 37, 1306, 180, 1533]]"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "input_sequence = []\n",
        "for sentence in num_representation:\n",
        "  for i in range(1, len(sentence)):\n",
        "    input_sequence.append(sentence[0:i+1])\n",
        "input_sequence[:6]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "B23adcZQtBxt"
      },
      "outputs": [],
      "source": [
        "max_len = max([len(x) for x in input_sequence ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBwCWcPLxSNk",
        "outputId": "9f957563-4818-4c35-e049-3bc7856463eb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "max_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "g4li3aRMuYs6"
      },
      "outputs": [],
      "source": [
        "input_sequence_tensor= [torch.tensor(seq) for seq in input_sequence]\n",
        "padded_input_sequence = pad_sequence(input_sequence_tensor, padding_side=\"left\", padding_value=0, batch_first=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "padded_input_sequence.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHkXv2qZDDvx",
        "outputId": "8201fc13-4236-41c8-9750-9864985bf2af"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([124905, 40])"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "padded_input_sequence[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JNOR9uGDRct",
        "outputId": "f01e21ad-5d8a-458b-b608-9e5351d3ea17"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,  528, 2053])"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "padded_input_sequence.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpX0BRM31Hkb",
        "outputId": "b0d088ca-c7a4-466a-b095-8f2cb472b1a4"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([124905, 40])"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = padded_input_sequence[:, :-1]\n",
        "y = padded_input_sequence[:, -1:]\n",
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzf7n5Bh1JXC",
        "outputId": "cfc7d23a-14b3-435b-de8d-c6c2a9abbd0c"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([124905, 39])"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = torch.squeeze(one_hot(y, num_classes=len(word_dict)+1))\n",
        "y.shape"
      ],
      "metadata": {
        "id": "SV6c_T5D22Y9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3047180-0617-421f-fed6-885f9c38972e"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([124905, 2065])"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8vEgbmcEjFP",
        "outputId": "38c6f78b-dbb7-40ab-d5ea-35566e372ee6"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0,  ..., 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class mydata(Dataset):\n",
        "  def __init__(self, X, y):\n",
        "    super().__init__()\n",
        "    self.X = X\n",
        "    self.y = y\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.y)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.X[idx], self.y[idx]"
      ],
      "metadata": {
        "id": "_L7UgN8X5onm"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = mydata(X, y)\n",
        "batched_data = DataLoader(data, batch_size=128, shuffle=True)"
      ],
      "metadata": {
        "id": "Zpp3kc2X6SQm"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "tPizzyUa2T-T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class next_word_predictor(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.embd = nn.Embedding(len(word_dict)+1, 100)\n",
        "    self.do = nn.Dropout(0.2)\n",
        "    self.lstm = nn.LSTM(input_size=100, hidden_size=150, num_layers=2, batch_first=True)\n",
        "    self.fc1 = nn.Linear(150, len(word_dict)+1)\n",
        "    self.fc2 = nn.Linear(len(word_dict)+1, len(word_dict)+1)\n",
        "\n",
        "    # self.sf = nn.Softmax(dim = 1)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.embd(x)\n",
        "    x = self.do(x)\n",
        "    h, c = self.lstm(x)\n",
        "    y = self.fc1(h[:, -1, :])\n",
        "    y = self.fc2(y)\n",
        "    # y = self.sf(y)\n",
        "    return(y)"
      ],
      "metadata": {
        "id": "FRJ0aOSw7GF-"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = next_word_predictor()\n",
        "model.to(device)\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofRsVnea_CAH",
        "outputId": "9e0c21c0-dec2-4dc6-f613-198ebf95c5db"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "next_word_predictor(\n",
              "  (embd): Embedding(2065, 100)\n",
              "  (do): Dropout(p=0.2, inplace=False)\n",
              "  (lstm): LSTM(100, 150, num_layers=2, batch_first=True)\n",
              "  (fc1): Linear(in_features=150, out_features=2065, bias=True)\n",
              "  (fc2): Linear(in_features=2065, out_features=2065, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(epochs = 50):\n",
        "  model.train()\n",
        "  loss_fn = nn.CrossEntropyLoss()\n",
        "  optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    for batch in batched_data:\n",
        "      losses = []\n",
        "      X, y = batch\n",
        "      X, y = X.to(device), y.to(device)\n",
        "      y_pred = model(X)\n",
        "\n",
        "      loss = loss_fn(y_pred, torch.argmax(y, dim=1))\n",
        "\n",
        "      loss.backward()\n",
        "      losses.append(loss.item())\n",
        "      optim.step()\n",
        "      optim.zero_grad()\n",
        "\n",
        "    print(f\"Epoch: {epoch}, Loss: {np.mean(losses)}\")"
      ],
      "metadata": {
        "id": "vnkREyD7-T16"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlJHVSIJBAT7",
        "outputId": "7cae9db7-bdaf-4445-df73-494433d74b98"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Loss: 0.792807936668396\n",
            "Epoch: 1, Loss: 0.7821967601776123\n",
            "Epoch: 2, Loss: 0.8900249600410461\n",
            "Epoch: 3, Loss: 0.7868149280548096\n",
            "Epoch: 4, Loss: 0.7283309698104858\n",
            "Epoch: 5, Loss: 0.5019057393074036\n",
            "Epoch: 6, Loss: 0.7960450649261475\n",
            "Epoch: 7, Loss: 0.39992251992225647\n",
            "Epoch: 8, Loss: 0.6067790985107422\n",
            "Epoch: 9, Loss: 0.5627151131629944\n",
            "Epoch: 10, Loss: 0.5698567628860474\n",
            "Epoch: 11, Loss: 0.5483987331390381\n",
            "Epoch: 12, Loss: 0.3848839998245239\n",
            "Epoch: 13, Loss: 0.6082321405410767\n",
            "Epoch: 14, Loss: 0.5442816019058228\n",
            "Epoch: 15, Loss: 0.5714972019195557\n",
            "Epoch: 16, Loss: 0.6952379941940308\n",
            "Epoch: 17, Loss: 0.5653643608093262\n",
            "Epoch: 18, Loss: 0.36873525381088257\n",
            "Epoch: 19, Loss: 0.3148738741874695\n",
            "Epoch: 20, Loss: 0.4792240560054779\n",
            "Epoch: 21, Loss: 0.612885057926178\n",
            "Epoch: 22, Loss: 0.6372615098953247\n",
            "Epoch: 23, Loss: 0.5257134437561035\n",
            "Epoch: 24, Loss: 0.500193178653717\n",
            "Epoch: 25, Loss: 0.3640625774860382\n",
            "Epoch: 26, Loss: 0.5971618890762329\n",
            "Epoch: 27, Loss: 0.4665842652320862\n",
            "Epoch: 28, Loss: 0.5942273139953613\n",
            "Epoch: 29, Loss: 0.584631085395813\n",
            "Epoch: 30, Loss: 0.38087764382362366\n",
            "Epoch: 31, Loss: 0.3917449116706848\n",
            "Epoch: 32, Loss: 0.5956963896751404\n",
            "Epoch: 33, Loss: 0.5269200205802917\n",
            "Epoch: 34, Loss: 0.43226704001426697\n",
            "Epoch: 35, Loss: 0.39959341287612915\n",
            "Epoch: 36, Loss: 0.4522411823272705\n",
            "Epoch: 37, Loss: 0.40612250566482544\n",
            "Epoch: 38, Loss: 0.4246463179588318\n",
            "Epoch: 39, Loss: 0.4672713875770569\n",
            "Epoch: 40, Loss: 0.28157949447631836\n",
            "Epoch: 41, Loss: 0.6796005964279175\n",
            "Epoch: 42, Loss: 0.47435638308525085\n",
            "Epoch: 43, Loss: 0.35188597440719604\n",
            "Epoch: 44, Loss: 0.5808795094490051\n",
            "Epoch: 45, Loss: 0.35713106393814087\n",
            "Epoch: 46, Loss: 0.415621817111969\n",
            "Epoch: 47, Loss: 0.5037194490432739\n",
            "Epoch: 48, Loss: 0.5369551777839661\n",
            "Epoch: 49, Loss: 0.2698241174221039\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word = 'girl'\n",
        "num_word = word_dict[word]\n",
        "num_word = torch.tensor(num_word).to(device)\n",
        "num_word = num_word.unsqueeze(0)"
      ],
      "metadata": {
        "id": "V3_BTrltIO7H"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "CNeDmQh8Klf_"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_word = (F.pad(num_word, (max_len-(len(num_word)+1), 0), value=0)).reshape(1, 39)\n",
        "padded_word.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HvSzNhHJpdZ",
        "outputId": "fae7f673-fa38-4ba1-e395-8bf9f3b69c74"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 39])"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model(padded_word)"
      ],
      "metadata": {
        "id": "5Uy3QtJ8Lqqo"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQnF9saXKlWt",
        "outputId": "97df3fd8-44f5-459d-e658-02488a8d8152"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 2065])"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.argmax(pred)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akAE7hBqOQT4",
        "outputId": "3153540f-7407-456c-9882-5ab18ab45018"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(122, device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(i_to_w[torch.argmax(pred).item()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjWH7GUJPZeN",
        "outputId": "2919a45c-c9b9-4552-e526-a0ed93466bec"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "are\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "sentence = 'why you'\n",
        "for i in range(3):\n",
        "  sent_word = []\n",
        "  for words in sentence.split(' '):\n",
        "    num_word = word_dict[words]\n",
        "    sent_word.append(num_word)\n",
        "\n",
        "    padded_word = (F.pad(torch.tensor(sent_word).to(device), (max_len-(len(sent_word)+1), 0), value=0)).reshape(1, 39)\n",
        "    pred = model(padded_word)\n",
        "    time.sleep(1)\n",
        "    sentence = sentence + \" \" + (i_to_w[torch.argmax(pred).item()])\n",
        "    print(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5_LNfkC36U0",
        "outputId": "caba5f26-607f-4fd7-9d6a-24b142d2503d"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "why you pay\n",
            "why you pay know\n",
            "why you pay know pay\n",
            "why you pay know pay seen\n",
            "why you pay know pay seen for\n",
            "why you pay know pay seen for are\n",
            "why you pay know pay seen for are pay\n",
            "why you pay know pay seen for are pay have\n",
            "why you pay know pay seen for are pay have to\n",
            "why you pay know pay seen for are pay have to a\n",
            "why you pay know pay seen for are pay have to a from\n",
            "why you pay know pay seen for are pay have to a from you\n",
            "why you pay know pay seen for are pay have to a from you me\n",
            "why you pay know pay seen for are pay have to a from you me we\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}